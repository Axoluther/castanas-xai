{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11927074,"sourceType":"datasetVersion","datasetId":7498726}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Castañas\n\nEn este documento se va a crear un modelo para las castañas para su posterior análisis con XAI","metadata":{}},{"cell_type":"markdown","source":"## Carga de datos ya aumentados","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom matplotlib import pyplot as plt\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T00:33:23.251085Z","iopub.execute_input":"2025-05-24T00:33:23.251809Z","iopub.status.idle":"2025-05-24T00:33:36.230335Z","shell.execute_reply.started":"2025-05-24T00:33:23.251778Z","shell.execute_reply":"2025-05-24T00:33:36.229783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/castanas-aug-ds/castanas_aug_ds'\n\ntrain, val = keras.utils.image_dataset_from_directory (\n    directory=dataset_dir,\n    batch_size=32,\n    shuffle=True,\n    labels=\"inferred\" ,\n    class_names= [\"no_comible\", \"comible\"],\n    label_mode='binary',\n    color_mode='rgb',\n    image_size=(256,256),\n    validation_split=0.2,\n    subset='both',\n    seed=69,\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T00:33:36.231332Z","iopub.execute_input":"2025-05-24T00:33:36.231771Z","iopub.status.idle":"2025-05-24T00:33:41.226959Z","shell.execute_reply.started":"2025-05-24T00:33:36.231744Z","shell.execute_reply":"2025-05-24T00:33:41.226388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def ver_imgs(dataset: tf.data.Dataset):\n    clases = ['no comible', 'comible']\n    plt.figure(figsize=(5,5))\n    # plt.subplots_adjust(hspace=10)\n\n    imgs, labels = next(iter(dataset.take(1)))\n\n    for i in range(3):\n        img, label = imgs[i], labels[i]\n        ax = plt.subplot(1,3,i+1)\n        ax.set_axis_off()\n        plt.imshow( img.numpy().astype('uint8') )\n        plt.title ( clases[int(label.numpy())])\n\n\n    plt.tight_layout()\n    plt.show()\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T00:35:37.834709Z","iopub.execute_input":"2025-05-24T00:35:37.835315Z","iopub.status.idle":"2025-05-24T00:35:37.840344Z","shell.execute_reply.started":"2025-05-24T00:35:37.835292Z","shell.execute_reply":"2025-05-24T00:35:37.839605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ver_imgs(train)\nver_imgs(val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T00:35:40.014040Z","iopub.execute_input":"2025-05-24T00:35:40.014745Z","iopub.status.idle":"2025-05-24T00:35:40.760542Z","shell.execute_reply.started":"2025-05-24T00:35:40.014717Z","shell.execute_reply":"2025-05-24T00:35:40.759840Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modelo CNN","metadata":{}},{"cell_type":"code","source":"modificar_img = keras.Sequential([\n    keras.layers.RandomFlip('horizontal'),\n    keras.layers.RandomRotation(0.1),\n    keras.layers.RandomZoom(0.1),\n    keras.layers.RandomTranslation(0.1, 0.1),\n    keras.layers.RandomContrast(0.2)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T01:27:20.590243Z","iopub.execute_input":"2025-05-24T01:27:20.590802Z","iopub.status.idle":"2025-05-24T01:27:20.609449Z","shell.execute_reply.started":"2025-05-24T01:27:20.590777Z","shell.execute_reply":"2025-05-24T01:27:20.608683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = keras.Sequential([\n    keras.Input(shape=(256, 256, 3)),\n    keras.layers.Rescaling(1./255),\n    modificar_img, \n    #1\n    #agregado kernel_regularizer=keras.regularizers.l2(0.001)\n    keras.layers.Conv2D( filters=32, kernel_size=(5,5)),\n    # keras.layers.BatchNormalization(),\n    keras.layers.ReLU(),\n    keras.layers.MaxPool2D((2,2)),\n    # keras.layers.Dropout(0.2) ,\n    #2\n    keras.layers.Conv2D( filters=64, kernel_size=(7,7)),\n    # keras.layers.BatchNormalization(),\n    keras.layers.ReLU(),\n    keras.layers.MaxPool2D((2,2)),\n    # keras.layers.Dropout(0.2) ,\n    #3\n    keras.layers.Conv2D( filters=64, kernel_size=(3,3)),\n    # keras.layers.BatchNormalization(),\n    keras.layers.ReLU(),\n    keras.layers.MaxPool2D((2,2)),\n    # keras.layers.Dropout(0.2) ,\n    #4\n    keras.layers.Conv2D( filters=64, kernel_size=(3,3)),\n    # keras.layers.BatchNormalization(),\n    keras.layers.ReLU(),\n    keras.layers.MaxPool2D((2,2)),\n    # keras.layers.Dropout(0.2) ,\n    #5\n    keras.layers.Conv2D( filters=64, kernel_size=(3,3)),\n    # keras.layers.BatchNormalization(),\n    keras.layers.ReLU(),\n    keras.layers.MaxPool2D((2,2)),\n    # keras.layers.Dropout(0.2) ,\n    \n    #agregado drop 0.2->0.4, kernel_regularizer=keras.regularizers.l2(0.001)\n    keras.layers.Flatten(),\n    #1\n    keras.layers.Dense(units= 128),\n    # keras.layers.BatchNormalization(),\n    keras.layers.ReLU(),\n    # keras.layers.Dropout(0.4) ,\n    #2\n    keras.layers.Dense(units= 64),\n    # keras.layers.BatchNormalization(),\n    keras.layers.ReLU(),\n    # keras.layers.Dropout(0.2) ,\n    #3\n    keras.layers.Dense(units= 32),\n    # keras.layers.BatchNormalization(),\n    keras.layers.ReLU(),\n    # keras.layers.Dropout(0.2) ,\n    keras.layers.Dense(units= 1, activation='sigmoid'),\n],\ntrainable=True,\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T03:21:52.028423Z","iopub.execute_input":"2025-05-24T03:21:52.028746Z","iopub.status.idle":"2025-05-24T03:21:52.127248Z","shell.execute_reply.started":"2025-05-24T03:21:52.028725Z","shell.execute_reply":"2025-05-24T03:21:52.126686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stop = keras.callbacks.EarlyStopping(\n    monitor = 'val_loss',\n    patience = 4,\n    min_delta=0.001, #agregado\n    restore_best_weights = True,\n    )\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.0005 ),\n    # optimizer='adam',\n    loss=keras.losses.binary_crossentropy,\n    metrics=['accuracy'],\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T03:21:55.177995Z","iopub.execute_input":"2025-05-24T03:21:55.178554Z","iopub.status.idle":"2025-05-24T03:21:55.187272Z","shell.execute_reply.started":"2025-05-24T03:21:55.178533Z","shell.execute_reply":"2025-05-24T03:21:55.186677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train,\n    epochs=10, \n    validation_data=val,\n    callbacks = [early_stop],\n    class_weight={0: 1.5, 1: 1.0}, #agregado, utillll\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T03:21:57.095987Z","iopub.execute_input":"2025-05-24T03:21:57.096468Z","iopub.status.idle":"2025-05-24T03:22:33.484973Z","shell.execute_reply.started":"2025-05-24T03:21:57.096446Z","shell.execute_reply":"2025-05-24T03:22:33.484175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p \"/kaggle/working/modelos/\"\nmodel.save(\"/kaggle/working/modelos/Castanas_Model_1_91.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T03:26:28.591317Z","iopub.execute_input":"2025-05-24T03:26:28.591660Z","iopub.status.idle":"2025-05-24T03:26:28.909358Z","shell.execute_reply.started":"2025-05-24T03:26:28.591631Z","shell.execute_reply":"2025-05-24T03:26:28.908684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nplt.plot(history.history['loss'], label = 'loss')\nplt.plot(history.history['val_loss'], label = 'val loss')\n\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='lower right')\n\nval_loss, val_acc = model.evaluate(val, verbose=2)\nprint(f'val accuaricy: {val_acc} val loss: {val_loss}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T03:16:33.961093Z","iopub.execute_input":"2025-05-24T03:16:33.961387Z","iopub.status.idle":"2025-05-24T03:16:34.389501Z","shell.execute_reply.started":"2025-05-24T03:16:33.961366Z","shell.execute_reply":"2025-05-24T03:16:34.388851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Obtener una sola imagen del batch\n# `img1` es de forma (32, 256, 256, 3), por lo que seleccionamos una sola imagen:\nimg_single = img1[0].numpy() / 255.0  # (256, 256, 3)\n\n# Expandir dimensiones para hacerla (1, 256, 256, 3), que es lo que espera el modelo\nimg_single_batch = np.expand_dims(img_single, axis=0)\n\n# Pasar una sola imagen al modelo\n_ = model(img_single_batch)\n\n# Crear extractor de características\ninput = model.layers[0].input\nintermediate_layer = model.get_layer(index=14)\noutput = intermediate_layer.output\nfeature_extractor = keras.models.Model(inputs=input, outputs=output)\n\n# Obtener feature maps\nfeature_maps = feature_extractor.predict(img_single_batch)\n\nprint(\"Forma de feature_maps:\", feature_maps.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T03:18:45.218527Z","iopub.execute_input":"2025-05-24T03:18:45.219191Z","iopub.status.idle":"2025-05-24T03:18:45.466786Z","shell.execute_reply.started":"2025-05-24T03:18:45.219168Z","shell.execute_reply":"2025-05-24T03:18:45.466193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Número de filtros\nnum_filters = feature_maps.shape[-1]\ncols = 3\nrows = math.ceil((num_filters + 1) / cols)\n\n# Plotear imagen y filtros\nplt.figure(figsize=(5 * cols, 5 * rows))\n\n# Imagen original\nplt.subplot(rows, cols, 1)\nplt.imshow(img_single)\nplt.title('Imagen de entrada')\nplt.axis('off')\n\n# Filtros\nfor i in range(num_filters):\n    plt.subplot(rows, cols, i + 2)\n    plt.imshow(feature_maps[0, :, :, i], cmap='viridis')\n    plt.title(f'Filtro {i}')\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T03:18:46.797002Z","iopub.execute_input":"2025-05-24T03:18:46.797516Z","iopub.status.idle":"2025-05-24T03:18:51.674884Z","shell.execute_reply.started":"2025-05-24T03:18:46.797470Z","shell.execute_reply":"2025-05-24T03:18:51.674119Z"}},"outputs":[],"execution_count":null}]}